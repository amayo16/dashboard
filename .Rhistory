}
summary(Accuracies)
plot(density(Accuracies))
H4A_swfq <- stepclass(H4A[2:72], H4A$PopSex, "qda", improvement = 0.005,, fold = 5, maxvars = 15)
# multiple times
Accuracies <- c(0.00)
# best QDFA model:
# H4A$PopSex ~ GOL + XCB + OBH + XML + FOL + VRR
for (i in seq(1000))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
# testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
H4A.RB <- qda(PopSex ~ GOL + XCB + OBH + XML + FOL + VRR, data = H4A, prior =
c(0.25,0.25,0.25,0.25), subset = -inTrain, CV = T)
Accuracies[i] <- confusionMatrix(H4A[as.numeric(rownames(H4A.RB$posterior)),"PopSex"],
H4A.RB$class)$overall["Accuracy"]
}
summary(Accuracies)
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv")) update(knn4, list(.k = 3))
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4 <- train(PopSex ~ ., data = training, method = "knn",
tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
confusionMatrix(knn4)
knn4_pred <- predict(knn4,newdata = testing)
confusionMatrix(knn4_pred,testing$PopSex)
Accuracies <- c(0.00)
# best QDFA model:
# H4A$PopSex ~ GOL + XCB + OBH + XML + FOL + VRR
for (i in seq(20)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
# testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
knn4 <- train(PopSex ~ ., data = training, method = "knn",
preProcess = c("center", "scale"), tuneLength = 10,
trControl = trainControl(method = "cv"))
update(knn4, list(.k = 3))
knn4_pred <- predict(knn4,newdata = testing)
Accuracies[i] <- confusionMatrix(knn4_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
####Blog Post 2#####
library(Lahman)
library(dplyr)
library(ggiraph)
library(ggplot2)
#Store the HR and SO data into a dataframe
df <- Batting%>%
group_by(playerID)%>%
summarize(Career_HR = sum(HR),Career_SO = sum(SO))%>%
filter(Career_HR >= 400)
#Join the dataframe with the Master table.  Bring in the first and last name of the player.
HR_vs_SO <- inner_join(df,Master,by=c("playerID"))%>%
select(nameFirst,nameLast,Career_HR,Career_SO)
#----------------------------------------------------
#Creating the scatterplot.
g<-ggplot()+
geom_point_interactive(data = HR_vs_SO, aes(x=Career_SO,y=Career_HR,tooltip=nameLast))+
ggtitle("Career Homeruns vs Strikeouts for Great Hitters")+
xlab("Career Strikouts")+
ylab("Career Homeruns")
ggiraph(code=print(g))
g
ggiraph(code=print(g))
HR_vs_SO$nameFirst
HR_vs_SO$nameLast
paste(HR_vs_SO$nameFirst,HR_vs_SO$nameLast)
HR_vs_SO$name <-paste(HR_vs_SO$nameFirst,HR_vs_SO$nameLast)
HR_vs_SO <- inner_join(df,Master,by=c("playerID"))%>%
select(name,Career_HR,Career_SO)
HR_vs_SO
g<-ggplot()+
geom_point_interactive(data = HR_vs_SO, aes(x=Career_SO,y=Career_HR,tooltip=name))+
ggtitle("Career Homeruns vs Strikeouts for Great Hitters")+
xlab("Career Strikouts")+
ylab("Career Homeruns")
ggiraph(code=print(g))
g<-ggplot()+
geom_point_interactive(data = HR_vs_SO, aes(x=Career_SO,y=Career_HR,tooltip=name,data_id=nameLast))+
ggtitle("Career Homeruns vs Strikeouts for Great Hitters")+
xlab("Career Strikouts")+
ylab("Career Homeruns")
ggiraph(code=print(g),hover_css="fill:white;stroke:black")
library(Lahman)
library(dply)
library(dplyr)
library(ggplot2)
library(ggiraph)
head(Master)
df <- Master%>%
select(weight)
df
ggplot()+
geom_histogram(data = df, aes(x=weight))
df <- Master%>%
filter(!is.na(weight))%>%
select(weight)
ggplot()+
geom_histogram(data = df, aes(x=weight))
ggplot()+
geom_histogram(data = df, aes(x=weight), color = "white")
ggplot()+
geom_histogram(data = df, aes(x=weight), color = "white", fill = "blue")
ggplot()+
geom_histogram(data = df, aes(x=weight), color = "white", fill = "blue")+
ggtitle("Baseball Player Weights")
ggplot()+
geom_histogram(data = df, aes(x=weight), color = "white", fill = "blue", bins = 10)+
ggtitle("Baseball Player Weights")
ggplot()+
geom_histogram(data = df, aes(x=weight), color = "white", fill = "blue", bins = 25)+
ggtitle("Baseball Player Weights")
ggplot()+
geom_histogram(data = df, aes(x=weight), color = "white", fill = "blue", bins = 30)+
ggtitle("Baseball Player Weights")
help(gglab)
help("ggplot")
df <- Teams%>%
filter(yearID == 1980)%>%
select(teamdID,HR)
###Barplot###
df <- Teams%>%
filter(yearID == 1980)%>%
select(teamID ,HR)
df
ggplot()+
geom_bar(data = df, aes(x = teamID, y = HR), stat = "identity")
ggplot()+
geom_bar(data = df, aes(x = teamID, y = HR), stat = "identity", color = "white", fill = "blue")
ggplot()+
geom_bar(data = df, aes(x = teamID, y = HR), stat = "identity", color = "blue", fill = "white")
head(Teams)
df <- Teams%>%
filter(yearID == 1980)%>%
select(name , HR)
ggplot()+
geom_bar(data = df, aes(x = names, y = HR), stat = "identity", color = "blue", fill = "white")
ggplot()+
geom_bar(data = df, aes(x = name, y = HR), stat = "identity", color = "blue", fill = "white")
ggplot()+
geom_bar(data = df, aes(x = HR, y = name), stat = "identity", color = "blue", fill = "white")  #ggplot does tallying for you.  Don't do any type of grouping because we already did it in the function.
ggplot()+
geom_bar(data = df, aes(x = name, y = HR), stat = "identity", color = "blue", fill = "white")+ #ggplot does tallying for you.  Don't do any type of grouping because we already did it in the function.
coord_flip()
df <- Teams%>%
filter(yearID == 1980)%>%
select(name , HR)%>%
arrange(HR)
ggplot()+
geom_bar(data = df, aes(x = name, y = HR), stat = "identity", color = "blue", fill = "white")+ #ggplot does tallying for you.  Don't do any type of grouping because we already did it in the function.
coord_flip()
df <- Teams%>%
filter(yearID == 1980)%>%
select(name , HR)%>%
arrange(HR)
ggplot()+
geom_bar(data = df, aes(x = name, y = HR), stat = "identity", color = "blue", fill = "white")+ #ggplot does tallying for you.  Don't do any type of grouping because we already did it in the function.
coord_flip()
df
df$name
str(df$name)
str(df$HR)
df$name <- factor(df$name)
str(df$name)
ggplot()+
geom_bar(data = df, aes(x = name, y = HR), stat = "identity", color = "blue", fill = "white")+ #ggplot does tallying for you.  Don't do any type of grouping because we already did it in the function.
coord_flip()
levels(df$name)
df$name <- factor(df$name, levels = df$name)
ggplot()+
geom_bar(data = df, aes(x = name, y = HR), stat = "identity", color = "blue", fill = "white")+ #ggplot does tallying for you.  Don't do any type of grouping because we already did it in the function.
coord_flip()
levels(df$name)
Hef <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/HefM.csv', as.is = T);
str(hef)
str(Hef)
table(Hef$Pop)
HefNB <- na.omit(Hef)
Accuracies <- c(0.00)
for (i in seq(20)) # only 20 because it takes a while
{
inTrain <- createDataPartition(y = HefNB$Pop, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
library(caret)
Accuracies <- c(0.00)
for (i in seq(20)) # only 20 because it takes a while
{
inTrain <- createDataPartition(y = HefNB$Pop, # y = grouping variable,
stratified random split
p = .70, ## The proportion of records in the training set
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = HefNB$Pop,
stratified random split
p = .70,
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = HefNB$Pop, stratified random split,p = .70,
list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = HefNB$Pop, p = .70, list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
ctrl <- trainControl(method = "cv")
Accuracies <- c(0.00)
for (i in seq(20))
{
inTrain <- createDataPartition(y = HefNB$Pop, p = .70, list = FALSE)
train <- HefNB[inTrain,]
test <- HefNB[-inTrain,]
nb2 <- train(Pop ~ ANS+INA+IOB+NAW+NBS+NO+PBD+ZS, data = train, method
= "nb",
trControl = ctrl,
tuneGrid = data.frame(usekernel = TRUE, fL = 0.5, adjust
= 5))
bps2 <- predict(nb2, newdata = test)
Accuracies[i] <- confusionMatrix(test$Pop,bps2)$overall["Accuracy"]
}
summary(Accuracies)
plot(density(Accuracies))
confusionMatrix(test$Pop,bps2)
setwd("C:/Users/Andrew/Desktop/blog_2")
serve_site()
library(blogdown)
library(devtools)
serve_site()
build_site()
install.packages("sda")
library(sda)
library(caret)
Howells <- read.csv('http://math.mercyhurst.edu/~sousley/STAT_139/data/Howells.csv', as.is = T);
attach(Howells);
# this time get ALL predictors
HBNMF <- Howells[which(Pop == 'NORSE' | Pop == 'BERG'),];
# many columns are Nas
H4A <- na.omit(HBNMF[,c(5:61,63,67:80)])
H4A$PopSex <- as.factor(H4A$PopSex)
View(H4A)
Accuracies <- c(0.00)
for (i in seq(10))
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
# testrecs <- as.numeric(rownames(testing)) # row(testing)[,1]
H4A.RB <- train(PopSex ~ ., data = H4A, method = "sda", subset = -inTrain, CV = T)
Accuracies[i] <- confusionMatrix(H4A[as.numeric(rownames(H4A.RB$posterior)),"PopSex"],
H4A.RB$class)$overall["Accuracy"]
}
Accuracies <- c(0.00)
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda",
metric = metric, trControl = control, preProcess = c("center","scale")
sda1_pred <- predict(sda1, newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda",
metric = metric, trControl = control, preProcess = c("center","scale")
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda",
metric = metric, trControl = control, preProcess = c("center","scale"))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda",
metric = metric, trControl = trainControl(method = "cv"), preProcess = c("center","scale"))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda", trControl = trainControl(method = "cv"), preProcess = c("center","scale"))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
confusionMatrix(sda1_pred,testing$PopSex)
library(Lahman)
i
HistData
library(Lahman)
library(ggplot2)
library(dplyr)
install.packages("flexdashboard")
library(flexdashboard)
Batting%>%
filter(playerID == "ruthba01")%>%
select(SO, HR)
ggplot()+
geom_point(data = result, aes(x = SO, y = HR))
result <- Batting%>%
filter(playerID == "ruthba01")%>%
select(SO, HR)
ggplot()+
geom_point(data = result, aes(x = SO, y = HR))
ggplot()+
geom_point(data = result, aes(x = SO, y = HR))+
xlab("Strikeouts")+
ylab("Homeruns")
ggplot()+
geom_histogram(data = result, aes(x = HR))
ggplot()+
geom_histogram(data = result, aes(x = HR))+
xlab("Homeruns")
ggplot()+
geom_histogram(data = result, aes(x = HR), bins = 10)+
xlab("Homeruns")
ggplot()+
geom_histogram(data = result, aes(x = HR), bins = 10, color = blue, fill = white)+
xlab("Homeruns")
ggplot()+
geom_histogram(data = result, aes(x = HR), bins = 5, color = "blue", fill = "white")+
xlab("Homeruns")
result <- Batting%>%
filter(playerID == "ruthba01")%>%
select(SO, HR, yearID)
ggplot()+
geom_point(data = result, aes(x = yearID, y = HR))+
geom_line(data = result, aes(x = yearID, y = HR))
ggplot()+
geom_point(data = result, aes(x = yearID, y = HR))+
geom_line(data = result, aes(x = yearID, y = HR))+
xlab("Year")+
ylab("Homeruns")
setwd("C:/Users/Andrew/Desktop/Dashboard")
Accuracies
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda", trControl = trainControl(method = "cv"), preProcess = c("center","scale"))
update(sda1, list(.lambda = 3))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda", trControl = trainControl(method = "cv"), preProcess = c("center","scale"))
update(sda1, list(diagonal = 3,lambda = 3))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
confusionMatrix(sda1_pred,testing$PopSex)
Accuracies <- c(0.00)
for (i in seq(10)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda", trControl = trainControl(method = "cv"), preProcess = c("center","scale"))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
Accuracies <- c(0.00)
for (i in seq(500)) # only 20 befcause it takes a while
{
inTrain <- createDataPartition(y = H4A$PopSex, # y = grouping variable, stratified random split
## the outcome data are needed
p = .70, ## The proportion of records in the training set
list = FALSE)
training <- H4A[inTrain,]
testing <- H4A[-inTrain,]
sda1 <- train(PopSex ~ ., data = training, method = "sda", trControl = trainControl(method = "cv"), preProcess = c("center","scale"))
sda1_pred <- predict(sda1,newdata = testing)
Accuracies[i] <- confusionMatrix(sda1_pred,testing$PopSex)$overall["Accuracy"]
}
summary(Accuracies)
length(Accuracies)
confusionMatrix(sda1_pred,testing$PopSex)
sda1
sda1_pred
